---
title: Creating a task via API
layout: default
class: markdown
docson: true
interactive: true
followup:
  links:
    '/reference': API documentation for all TaskCluster services
---

This tutorial will show you how to create a task, as well as how to fetch
both state and artifacts from the task. Later tutorials will show you how to
listen for the events generated by task and how to combine this with custom
routes message.

---

## Constructing a Task Definition

To create a task we must construct a _task definition_, the API reference
documentation for the `queue.taskcluster.net` specifies a JSON schema for both
`queue.defineTask` and `queue.createTask` methods. You may find this schema at
`schemas.taskcluster.net/queue/v1/create-task-request.json`, for reference it
is rendered below.

<div data-render-schema="http://schemas.taskcluster.net/queue/v1/create-task-request.json#"></div>

As evident from the schema there is a few _required_ properties, such as:
`provisionerId`, `workerType`, `created`, `deadline`, `payload` and `metadata`.
The rest of the properties are optional and defaults should be documented.
It should, however, be noted that default values may change over time, so it
is recommended provide those you rely on.

All workers have a `workerType` this identifier is unique given the
`provisionerId`, hence, `provisionerId` and `workerType` uniquely identifies
the pool of workers you are submitting you task to. In practice the
`provisionerId` is embedded in scopes, such that different provisioners can
exist without interfering with each other. For the purpose of this tutorial we
shall use the `b2g-test` workerType from `aws-provisioner-v1`.

A task definition also includes a `created` timestamp, a `deadline` at which
point the _queue_ will resolve the task as `exception` unless the task has been
resolved earlier. This ensures that all tasks will eventually be resolved.
Timestamps are given in UTC as ISO 8601 formatted strings, the format which
`Date.toJSON()` returns. As evident below, `taskcluster-client` has some nice
utilities for constructing relative timestamps for this.

<pre data-plugin="interactive-example">
let taskcluster = require('taskcluster-client');

let task = {
  // Required properties
  provisionerId:      'aws-provisioner-v1',
  workerType:         'tutorial',
  created:            (new Date()).toJSON(),
  deadline:           taskcluster.fromNowJSON('2 days 3 hours'),
  metadata: {
    // Name and description are meant to be written in markdown
    name:             "Tutorial **Example** Task",
    description:      "Task create from _interactive_ tutorials",
    // Fill in your email
    owner:            'nobody@taskcluster.net',
    // Location of task source, so we can find people with "git blame"
    source:           window.location.href
  },
  payload:            {}, // worker specific payload, we'll add it later

  // There is more optional properties, but we don't need them here.
};

// Print example task definition
console.log(JSON.stringify(task, null, 2));
</pre>

In the example above you see how to specify the properties required by the
queue. If we were to submit this task to the queue it would be accepted,
however, the worker would immediately reject it because it doesn't carry a
valid `task.payload`. The `task.payload` is specific to the workerType given,
this way we can support multiple platforms and migrate tasks gradually,
keeping legacy workerTypes around until all tasks have been ported.

---

## Constructing a task payload for docker-worker

The `tutorial` workerType is a deployment of `docker-worker`, this worker
requires a `task.payload` that specifies which _docker image_ to load, which
command to run and a maximum allowed runtime. You can find detailed
documentation on this site, the schema for the `task.payload` property is
located at `schemas.taskcluster.net/docker-worker/v1/payload.json`, for
reference it is rendered below.

<div data-render-schema="http://schemas.taskcluster.net/docker-worker/v1/payload.json"></div>

For the `image` we can pick any docker image, take a look at
[registry.hub.docker.com](https://registry.hub.docker.com/), you can even build
and upload your own docker images. There are many benefits to using
custom docker images; notable ones include:

 * Install dependencies from package repositories and lock them,
 * Make custom scripts and binaries available in the runtime environment, and
 * Test docker images locally before deploying to TaskCluster.

There are many other benefits to docker, but an exhaustive list is beyond the
scope of this document. If you are not familiar with docker you should play
around with the official docker
[getting started guide](http://docs.docker.com/linux/started/). Deploying Linux
binaries in tasks on TaskCluster is mostly about getting the binaries to run
inside a docker container. For the most part this involves installing
dependencies and configuring them, so become familiar with docker before you
start deploying Linux tasks on TaskCluster.

For the purpose of this tutorial we'll use the official `ubuntu:15.04` docker
image. To make it interesting we'll run two commands `ls && du /usr` that should
show us a little of what the image contains. The example below shows how to
add a payload to the task definition from before.

<pre data-plugin="interactive-example">
let taskcluster = require('taskcluster-client');

let task = {
  provisionerId:      'aws-provisioner-v1',
  workerType:         'tutorial',
  created:            (new Date()).toJSON(),
  deadline:           taskcluster.fromNowJSON('2 days 3 hours'),
  metadata: {
    name:             "Tutorial **Example** Task",
    description:      "Task create from _interactive_ tutorials",
    owner:            'nobody@taskcluster.net',
    source:           window.location.href
  },
  payload: {
    // Properties required by docker-worker
    image:            'ubuntu:15.04',
    command:          ['/bin/bash', '-c', 'ls && du /usr'],
    maxRunTime:       600, // in seconds (600s = 10 minutes)
    // Optional properties
    artifacts: {
      // Export an artifact with the name "public/passwd.txt" and
      // take it from '/etc/passwd' after the task has run.
      "public/passwd.txt": {
        type:         'file',
        path:         '/etc/passwd',
        expires:      taskcluster.fromNowJSON('2 months')
      }
    }
  }
};

// Print example task definition
console.log(JSON.stringify(task, null, 2));
</pre>

To make things a little interesting the example above also exports the file
`/etc/passwd` as an artifact with the name `public/passwd.txt`. It should be
noted that all artifact names that starts with `public/` are public and
accessing them doesn't require any credentials.

---

## Creating a Task

All tasks have a `taskId` this is
[UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier)
, version 4. To better fit these UUIDs into URLs,
RabbitMQ routing keys and many other places we always encoded them in
[URL-safe base64](http://tools.ietf.org/html/rfc4648#section-5)
stripped of `==` padding. This yields a 22 character identifier like
`a8_YezW8T7e1jLxG7evy-A`.

We call an identifier on this form a _slugid_, in Javascript we can generate
them using the `slugid()` method of the `taskcluster-client` module. Being
based on UUID version 4 the risk of `taskId` collision is extremely small. In
fact if you encounter an error telling you that a given `taskId` is already
used by another task, it is most likely a problem with your retry logic that
fails to make idempotent requests, or you accidentally reused the `taskId`. The
example below shows how to generate a random slugid for use as `taskId`.

<pre data-plugin="interactive-example">
let taskcluster = require('taskcluster-client');

// Generate a new taskId
let taskId = taskcluster.slugid();

// Print the taskId
console.log("Randomly generated taskId: " + taskId);
</pre>

When we have a `taskId` and a _task definition_, we are ready to create a task.
In the example below we'll generate a random `taskId` store it on the `global`
object for use in later examples. Then we construct a task definition, a
`taskcluster.Queue` client with temporary credentials and create a new task
using the `queue.createTask(taskId, payload)` method, where `payload` is the
task definition.

<pre data-plugin="interactive-example">
let taskcluster = require('taskcluster-client');

// Generate a new taskId
let taskId = taskcluster.slugid();

// Store taskId for use in later examples to fetch status and artifacts
global.taskId = taskId;

// Task definition from previous example
let task = {
  provisionerId:      'aws-provisioner-v1',
  workerType:         'tutorial',
  created:            (new Date()).toJSON(),
  deadline:           taskcluster.fromNowJSON('2 days 3 hours'),
  metadata: {
    name:             "Tutorial **Example** Task",
    description:      "Task create from _interactive_ tutorials",
    owner:            'nobody@taskcluster.net',
    source:           window.location.href
  },
  payload: {
    // Properties required by docker-worker
    image:            'ubuntu:15.04',
    command:          ['/bin/bash', '-c', 'ls && du /usr'],
    maxRunTime:       600, // in seconds (600s = 10 minutes)
    // Optional properties
    artifacts: {
      // Export an artifact with the name "public/passwd.txt" and
      // take it from '/etc/passwd' after the task has run.
      "public/passwd.txt": {
        type:         'file',
        path:         '/etc/passwd',
        expires:      taskcluster.fromNowJSON('2 months')
      }
    }
  }
};

if (localStorage.credentials === undefined) {
  console.log("You must authenticate first - see Authenticate tutorial");
  return;
}

// Create a Queue client object w. temporary credentials
let queue = new taskcluster.Queue({
  credentials: JSON.parse(localStorage.credentials)
});

// Create task
let result = await queue.createTask(taskId, task);

// Print results
console.log("Created task:\n" + JSON.stringify(result.status, null, 2));
console.log("Inspect it at:");
console.log("https://tools.taskcluster.net/task-inspector/#" + taskId);
</pre>

Note that it may take a few minutes for this task to execute, as TaskCluster must
create a new Amazon EC2 instance to run it.

If you are curious about the `createTask(taskId, payload)` method you can look
it up in the [API docs](/services/platform/queue/api-docs/) for the Queue. You should notice that
the API docs lists a `Signature` property, like
`Signature: createTask(taskId, payload) : result`, these signature are used to
call methods in automatically generated client libraries. This allows for
consistent and well-documented client libraries across all platforms.

---

## Fetch for Task State

Holding the `taskId` to a task, we can fetch the task status, using the
`queue.status(taskId)` API end-point. This returns an object where the `status`
property is the _task status structure_. This structure is commonly used to
represent the status of a task in both API calls and pulse messages.
Below is the JSON schema for the response from the `queue.status(taskId)`
API end-point.

<div data-render-schema="http://schemas.taskcluster.net/queue/v1/task-status-response.json"></div>

In the following example we use the `queue.status(taskId)` API endpoint to
fetch status for the task created earlier. Recall that we stored the `taskId`
in `global.taskId`, so it should be present here unless you refreshed the
browser window. Notice that inspecting a task doesn't require any credentials,
you just need the `taskId`. We generally allow users to inspect metadata
without any credentials, which lets you easily create custom dashboards
and other useful tools.

<pre data-plugin="interactive-example">
let taskcluster = require('taskcluster-client');
let assert      = require('assert');

// Check that we have a taskId on global object from previous example
assert(global.taskId, "You must create a task with a taskId first!");

// Create Queue client object (no credentials needed for queue.status())
let queue = new taskcluster.Queue();

// Fetch task status, given the taskId from the `global` object
let result = await queue.status(global.taskId);

// Print status
if (['completed', 'failed', 'exception'].indexOf(result.status.state) !== -1) {
  console.log("Task is now resolved... continue to next step");
} else {
  console.log("Task isn't resolved yet, you can inspect it at:");
  console.log("https://tools.taskcluster.net/task-inspector/#" + global.taskId);
}
console.log("\nTask status structure:");
console.log(JSON.stringify(result.status, null, 2));
</pre>

You may notice that the _task status structure_ has a list of runs. Each run
have a `reasonCreated` and once resolved a `reasonResolved`. A run cannot
change state once resolved, but a task may have additional runs until
`task.deadline` is reached.

The queue creates additional runs, if a run fails because a worker became
unresponsive or reported a shutdown, for example if a node crashes or a
EC2 spot-node is terminated. In this case the task will be _retried_ at most
`task.retries` times. If you don't want your task to be retried you can set
`task.retries` to zero. Users can also _rerun_ a resolved task using
`queue.rerunTask(taskId)`, this is generally not recommended, especially not if
relying on another service for scheduling dependent tasks.

You should note the difference in terminology between:
 * **retry task**, which happens in case of infrastructure failure, and,
 * **rerun task**, which happens if explicitly requested by a caller.
The distinction is important as a task that is automatically _retried_ won't
cause a task exception message to published on pulse. Whereas a message
signaling that the task is resolved will be published on pulse before
calling `task.rerunTask(taskId)` as any effect.

---

## Download Task Artifacts

Once the task is resolved, or just the first run, we can list artifacts from
runs of the task. A convenience method `queue.listLatestArtifacts` will list
artifacts from the latest run. But you can also specify the exact run to
list artifacts from, or download the status structure to find the latest run.

In the example below we list artifacts from the latest run, `runId` always
starts from zero and highest `runId` is always the latest. As we don't want to
fetch the task status structure first we use
`queue.listLatestArtifacts(taskId)` instead of
`queue.listArtifacts(taskId, runId)`. Again, no credentials are required to
inspect the list of artifacts.

<pre data-plugin="interactive-example">
let taskcluster = require('taskcluster-client');
let assert      = require('assert');

// Check that we have a taskId on global object from previous example
assert(global.taskId, "You must create a task w. a taskId first!");

// Create Queue client object
let queue = new taskcluster.Queue();

// Fetch artifacts using taskId from global object
let result = await queue.listLatestArtifacts(global.taskId);

// Print list of artifacts
console.log(JSON.stringify(result, null, 2));
</pre>

As we list artifacts we should see an artifact `public/logs/live.log` and
`public/passwd.txt`. The `public/logs/live.log` contains the task log, and
is streamed live directly from the worker while the task is running. After the
task is completed the `public/logs/live.log` will redirect to a file on S3.
The `public/passwd.txt` is the `/etc/passwd` file as exported from the
docker container after task execution.

In the example below we list all artifacts again, and constructs URLs from
which they can be downloaded. Then we download the task log and print it.
It should be noted that artifacts prefixed `public/` are public and downloading
them doesn't require any credentials.

<pre data-plugin="interactive-example">
let taskcluster = require('taskcluster-client');
let assert      = require('assert');
let request     = require('superagent-promise');

// Check that we have a taskId on global object from previous example
assert(global.taskId, "You must create a task w. a taskId first!");

// Get taskId from global object
let taskId = global.taskId;

// Create Queue client object
let queue = new taskcluster.Queue();

// Fetch artifacts from latest run of task
let result = await queue.listLatestArtifacts(taskId);

// Print url for each artifact
console.log("Artifacts:");
for (let artifact of result.artifacts) {
  // Build URL for the artifact
  let url = queue.buildUrl(queue.getLatestArtifact, taskId, artifact.name);
  // Print URL for artifact
  console.log(url);
}

// Fetch public/logs/live.log
let url = queue.buildUrl(queue.getLatestArtifact, taskId, 'public/logs/live.log');
let res = await request.get(url).end();

// Print task log
console.log("\nTask Log:");
console.log(res.text)
</pre>

The auxiliary method `queue.buildUrl` (not an API call) constructs a URL for
the API method given as first parameter with URL parameters given. This is
useful if you want to create a URL that can be passed around.
If the artifact was private (ie. didn't start with `public/`) we could have
constructed the `queue` object with credentials and used the auxiliary
method `queue.buildSignedUrl` which works like `queue.buildUrl`, with the only
difference that includes a signature in the query-string for the URL.
